### install litellm

Run the proxy with the provided configuration:

```bash
litellm --config litellm.config.yaml
```

The configuration loads multiple models so they are ready for use by the backend.
